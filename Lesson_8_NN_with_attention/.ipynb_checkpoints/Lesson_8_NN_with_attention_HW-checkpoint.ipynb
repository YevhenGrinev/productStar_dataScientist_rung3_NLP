{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e7beb91-0083-4bb9-a0f6-17eace0e189d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import deeppavlov as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf324cd6-d70d-4e96-884b-0aec22bca686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'classifiers',\n",
       "           'doc_retrieval',\n",
       "           'embedder',\n",
       "           'entity_extraction',\n",
       "           'faq',\n",
       "           'kbqa',\n",
       "           'multitask',\n",
       "           'ner',\n",
       "           'odqa',\n",
       "           'ranking',\n",
       "           'regressors',\n",
       "           'relation_extraction',\n",
       "           'russian_super_glue',\n",
       "           'sentence_segmentation',\n",
       "           'spelling_correction',\n",
       "           'squad'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.configs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3b588f0-1509-49ad-9229-2e8be2e5a5d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Struct({'qa_squad2_bert': PosixPath('/Users/evgenijgrinev/.pyenv/versions/3.10.10/lib/python3.10/site-packages/deeppavlov/configs/squad/qa_squad2_bert.json'),\n",
       "        'qa_multisberquad_bert': PosixPath('/Users/evgenijgrinev/.pyenv/versions/3.10.10/lib/python3.10/site-packages/deeppavlov/configs/squad/qa_multisberquad_bert.json'),\n",
       "        'squad_bert': PosixPath('/Users/evgenijgrinev/.pyenv/versions/3.10.10/lib/python3.10/site-packages/deeppavlov/configs/squad/squad_bert.json'),\n",
       "        'squad_ru_convers_distilrubert_6L': PosixPath('/Users/evgenijgrinev/.pyenv/versions/3.10.10/lib/python3.10/site-packages/deeppavlov/configs/squad/squad_ru_convers_distilrubert_6L.json'),\n",
       "        'squad_ru_convers_distilrubert_2L': PosixPath('/Users/evgenijgrinev/.pyenv/versions/3.10.10/lib/python3.10/site-packages/deeppavlov/configs/squad/squad_ru_convers_distilrubert_2L.json'),\n",
       "        'squad_ru_bert': PosixPath('/Users/evgenijgrinev/.pyenv/versions/3.10.10/lib/python3.10/site-packages/deeppavlov/configs/squad/squad_ru_bert.json')})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.configs.squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ed49c21-c437-4dca-8fe7-b31a388b902c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"dataset_reader\": {\n",
      "    \"class_name\": \"squad_dataset_reader\",\n",
      "    \"data_path\": \"{DOWNLOADS_PATH}/squad/\"\n",
      "  },\n",
      "  \"dataset_iterator\": {\n",
      "    \"class_name\": \"squad_iterator\",\n",
      "    \"seed\": 1337,\n",
      "    \"shuffle\": true\n",
      "  },\n",
      "  \"chainer\": {\n",
      "    \"in\": [\"context_raw\", \"question_raw\"],\n",
      "    \"in_y\": [\"ans_raw\", \"ans_raw_start\"],\n",
      "    \"pipe\": [\n",
      "      {\n",
      "        \"class_name\": \"torch_squad_transformers_preprocessor\",\n",
      "        \"vocab_file\": \"{TRANSFORMER}\",\n",
      "        \"do_lower_case\": \"{LOWERCASE}\",\n",
      "        \"max_seq_length\": 384,\n",
      "        \"in\": [\"question_raw\", \"context_raw\"],\n",
      "        \"out\": [\"bert_features\", \"subtokens\", \"split_context\"]\n",
      "      },\n",
      "      {\n",
      "        \"class_name\": \"squad_bert_mapping\",\n",
      "        \"do_lower_case\": \"{LOWERCASE}\",\n",
      "        \"in\": [\"split_context\", \"bert_features\", \"subtokens\"],\n",
      "        \"out\": [\"subtok2chars\", \"char2subtoks\"]\n",
      "      },\n",
      "      {\n",
      "        \"class_name\": \"squad_bert_ans_preprocessor\",\n",
      "        \"do_lower_case\": \"{LOWERCASE}\",\n",
      "        \"in\": [\"ans_raw\", \"ans_raw_start\", \"char2subtoks\"],\n",
      "        \"out\": [\"ans\", \"ans_start\", \"ans_end\"]\n",
      "      },\n",
      "      {\n",
      "        \"class_name\": \"torch_transformers_squad\",\n",
      "        \"pretrained_bert\": \"{TRANSFORMER}\",\n",
      "        \"save_path\": \"{MODEL_PATH}/model\",\n",
      "        \"load_path\": \"{MODEL_PATH}/model\",\n",
      "        \"optimizer\": \"AdamW\",\n",
      "        \"optimizer_parameters\": {\n",
      "          \"lr\": 2e-05,\n",
      "          \"weight_decay\": 0.01,\n",
      "          \"betas\": [0.9, 0.999],\n",
      "          \"eps\": 1e-06\n",
      "        },\n",
      "        \"learning_rate_drop_patience\": 2,\n",
      "        \"learning_rate_drop_div\": 2.0,\n",
      "        \"batch_size\": 10,\n",
      "        \"in\": [\"bert_features\"],\n",
      "        \"in_y\": [\"ans_start\", \"ans_end\"],\n",
      "        \"out\": [\"ans_start_predicted\", \"ans_end_predicted\", \"logits\", \"scores\", \"inds\"]\n",
      "      },\n",
      "      {\n",
      "        \"class_name\": \"squad_bert_ans_postprocessor\",\n",
      "        \"in\": [\"ans_start_predicted\", \"ans_end_predicted\", \"split_context\", \"subtok2chars\", \"subtokens\", \"inds\"],\n",
      "        \"out\": [\"ans_predicted\", \"ans_start_predicted\", \"ans_end_predicted\"]\n",
      "      }\n",
      "    ],\n",
      "    \"out\": [\"ans_predicted\", \"ans_start_predicted\", \"scores\"]\n",
      "  },\n",
      "  \"train\": {\n",
      "    \"show_examples\": false,\n",
      "    \"evaluation_targets\": [\"valid\"],\n",
      "    \"log_every_n_batches\": 250,\n",
      "    \"val_every_n_batches\": 500,\n",
      "    \"batch_size\": 10,\n",
      "    \"pytest_max_batches\": 2,\n",
      "    \"pytest_batch_size\": 5,\n",
      "    \"validation_patience\": 10,\n",
      "    \"metrics\": [\n",
      "      {\n",
      "        \"name\": \"squad_v1_f1\",\n",
      "        \"inputs\": [\"ans\", \"ans_predicted\"]\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"squad_v1_em\",\n",
      "        \"inputs\": [\"ans\", \"ans_predicted\"]\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"squad_v2_f1\",\n",
      "        \"inputs\": [\"ans\", \"ans_predicted\"]\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"squad_v2_em\",\n",
      "        \"inputs\": [\"ans\", \"ans_predicted\"]\n",
      "      }\n",
      "    ],\n",
      "    \"class_name\": \"torch_trainer\"\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"variables\": {\n",
      "      \"LOWERCASE\": false,\n",
      "      \"TRANSFORMER\": \"bert-base-cased\",\n",
      "      \"ROOT_PATH\": \"~/.deeppavlov\",\n",
      "      \"DOWNLOADS_PATH\": \"{ROOT_PATH}/downloads\",\n",
      "      \"MODELS_PATH\": \"{ROOT_PATH}/models\",\n",
      "      \"MODEL_PATH\": \"{MODELS_PATH}/squad_torch_bert/cased/{TRANSFORMER}\"\n",
      "    },\n",
      "    \"download\": [\n",
      "      {\n",
      "        \"url\": \"http://files.deeppavlov.ai/v1/squad/squad_torch_bert_cased.tar.gz\",\n",
      "        \"subdir\": \"{MODEL_PATH}\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(dp.configs.squad.squad_bert, 'r') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3985bd3a-1878-4162-844d-bdfb17d71206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from deeppavlov import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71bfff19-05ca-4797-bf24-e9baabd2dff8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 18:19:16.684 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/v1/squad/squad_torch_bert_cased.tar.gz download because of matching hashes\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "squad_en = build_model('squad_bert', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa520ac4-5407-4efa-9536-22821359c6a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a library for NLP and dialog systems'], [14], [1.0]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_en(['DeepPavlov is a library for NLP and dialog systems.'], ['What is DeepPavlov?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ca5412f-cecf-4967-8b4e-90537776abda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"dataset_reader\": {\n",
      "    \"class_name\": \"squad_dataset_reader\",\n",
      "    \"dataset\": \"SberSQuADClean\",\n",
      "    \"url\": \"http://files.deeppavlov.ai/datasets/sber_squad_clean-v1.1.tar.gz\",\n",
      "    \"data_path\": \"{DOWNLOADS_PATH}/squad_ru_clean/\"\n",
      "  },\n",
      "  \"dataset_iterator\": {\n",
      "    \"class_name\": \"squad_iterator\",\n",
      "    \"seed\": 1337,\n",
      "    \"shuffle\": true\n",
      "  },\n",
      "  \"chainer\": {\n",
      "    \"in\": [\n",
      "      \"context_raw\",\n",
      "      \"question_raw\"\n",
      "    ],\n",
      "    \"in_y\": [\n",
      "      \"ans_raw\",\n",
      "      \"ans_raw_start\"\n",
      "    ],\n",
      "    \"pipe\": [\n",
      "      {\n",
      "        \"class_name\": \"torch_squad_transformers_preprocessor\",\n",
      "        \"vocab_file\": \"{TRANSFORMER}\",\n",
      "        \"do_lower_case\": \"{LOWERCASE}\",\n",
      "        \"max_seq_length\": 384,\n",
      "        \"in\": [\n",
      "          \"question_raw\",\n",
      "          \"context_raw\"\n",
      "        ],\n",
      "        \"out\": [\n",
      "          \"bert_features\",\n",
      "          \"subtokens\",\n",
      "          \"split_context\"\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"class_name\": \"squad_bert_mapping\",\n",
      "        \"do_lower_case\": \"{LOWERCASE}\",\n",
      "        \"in\": [\n",
      "          \"split_context\",\n",
      "          \"bert_features\",\n",
      "          \"subtokens\"\n",
      "        ],\n",
      "        \"out\": [\n",
      "          \"subtok2chars\",\n",
      "          \"char2subtoks\"\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"class_name\": \"squad_bert_ans_preprocessor\",\n",
      "        \"do_lower_case\": \"{LOWERCASE}\",\n",
      "        \"in\": [\n",
      "          \"ans_raw\",\n",
      "          \"ans_raw_start\",\n",
      "          \"char2subtoks\"\n",
      "        ],\n",
      "        \"out\": [\n",
      "          \"ans\",\n",
      "          \"ans_start\",\n",
      "          \"ans_end\"\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"class_name\": \"torch_transformers_squad\",\n",
      "        \"pretrained_bert\": \"{TRANSFORMER}\",\n",
      "        \"save_path\": \"{MODEL_PATH}/model\",\n",
      "        \"load_path\": \"{MODEL_PATH}/model\",\n",
      "        \"optimizer\": \"AdamW\",\n",
      "        \"optimizer_parameters\": {\n",
      "          \"lr\": 2e-05,\n",
      "          \"weight_decay\": 0.01,\n",
      "          \"betas\": [\n",
      "            0.9,\n",
      "            0.999\n",
      "          ],\n",
      "          \"eps\": 1e-06\n",
      "        },\n",
      "        \"learning_rate_drop_patience\": 3,\n",
      "        \"learning_rate_drop_div\": 2.0,\n",
      "        \"in\": [\n",
      "          \"bert_features\"\n",
      "        ],\n",
      "        \"in_y\": [\n",
      "          \"ans_start\",\n",
      "          \"ans_end\"\n",
      "        ],\n",
      "        \"out\": [\n",
      "          \"ans_start_predicted\",\n",
      "          \"ans_end_predicted\",\n",
      "          \"logits\",\n",
      "          \"scores\",\n",
      "          \"inds\"\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"class_name\": \"squad_bert_ans_postprocessor\",\n",
      "        \"in\": [\n",
      "          \"ans_start_predicted\",\n",
      "          \"ans_end_predicted\",\n",
      "          \"split_context\",\n",
      "          \"subtok2chars\",\n",
      "          \"subtokens\",\n",
      "          \"inds\"\n",
      "        ],\n",
      "        \"out\": [\n",
      "          \"ans_predicted\",\n",
      "          \"ans_start_predicted\",\n",
      "          \"ans_end_predicted\"\n",
      "        ]\n",
      "      }\n",
      "    ],\n",
      "    \"out\": [\n",
      "      \"ans_predicted\",\n",
      "      \"ans_start_predicted\",\n",
      "      \"scores\"\n",
      "    ]\n",
      "  },\n",
      "  \"train\": {\n",
      "    \"show_examples\": false,\n",
      "    \"evaluation_targets\": [\n",
      "      \"valid\"\n",
      "    ],\n",
      "    \"log_every_n_batches\": 250,\n",
      "    \"val_every_n_batches\": 500,\n",
      "    \"batch_size\": 10,\n",
      "    \"validation_patience\": 10,\n",
      "    \"metrics\": [\n",
      "      {\n",
      "        \"name\": \"squad_v1_f1\",\n",
      "        \"inputs\": [\n",
      "          \"ans\",\n",
      "          \"ans_predicted\"\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"squad_v1_em\",\n",
      "        \"inputs\": [\n",
      "          \"ans\",\n",
      "          \"ans_predicted\"\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"squad_v2_f1\",\n",
      "        \"inputs\": [\n",
      "          \"ans\",\n",
      "          \"ans_predicted\"\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"squad_v2_em\",\n",
      "        \"inputs\": [\n",
      "          \"ans\",\n",
      "          \"ans_predicted\"\n",
      "        ]\n",
      "      }\n",
      "    ],\n",
      "    \"class_name\": \"torch_trainer\"\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"variables\": {\n",
      "      \"LOWERCASE\": false,\n",
      "      \"TRANSFORMER\": \"DeepPavlov/rubert-base-cased\",\n",
      "      \"ROOT_PATH\": \"~/.deeppavlov\",\n",
      "      \"DOWNLOADS_PATH\": \"{ROOT_PATH}/downloads\",\n",
      "      \"MODELS_PATH\": \"{ROOT_PATH}/models\",\n",
      "      \"MODEL_PATH\": \"{MODELS_PATH}/squad_ru_torch_bert/{TRANSFORMER}\"\n",
      "    },\n",
      "    \"download\": [\n",
      "      {\n",
      "        \"url\": \"http://files.deeppavlov.ai/v1/squad/squad_ru_torch_bert.tar.gz\",\n",
      "        \"subdir\": \"{MODELS_PATH}\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(dp.configs.squad.squad_ru_bert, 'r') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a015570-99d4-4ea8-b9b6-241d617f5226",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 18:26:49.462 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/v1/squad/squad_ru_torch_bert.tar.gz download because of matching hashes\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "squad_ru= build_model('squad_ru_bert', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf732393-a42c-4895-a642-c2e3287c93a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "title = \"Третье поколение алгоритма OpenAI научилось выполнять текстовые задания по нескольким примерам.\"\n",
    "\n",
    "text = \"\"\"\n",
    "Исследователи из OpenAI представили GPT-3 — алгоритм, который может выполнять разные задания по написанию текста на основе всего нескольких примеров. В новой версии используется та же архитектура, что и в предыдущем алгоритме GPT-2, однако разработчики увеличили количество используемых в модели параметров до 175 миллиардов, обучив модель на 570 гигабайтах текста. В итоге GPT-3 может отвечать на вопросы по прочитанному тексту, писать стихи, разгадывать анаграммы, решать простые арифметические примеры и даже переводить — и для этого ей нужно немного (от 10 до 100) примеров того, как именно это делать. Подробное описание работы алгоритма исследователи выложили на arXiv.org.\n",
    "\n",
    "Важное ограничение современных алгоритмов NLP (natural language processing) — зависимость от контекста: многие алгоритмы могут выполнять только те задачи, на выполнение которых они обучены. Например, если необходим алгоритм, который пишет стихи, его нужно обучить на большом корпусе стихов — желательно, в том стиле, в котором должно быть итоговое. Если обучение пройдет успешно, алгоритм сможет произвести что-то похожее на стих, но вот ответить на вопрос или составить список слов для кроссворда он уже не сможет.\n",
    "\n",
    "То, сколько данных понадобится для обучения NLP-алгоритма конкретной задаче, напрямую зависит от того, как алгоритм предобучен: если системе хорошо известны все требования грамматики языка, а генерировать осмысленные фразы он умеет изначально, то конкретно для обучения какой-то отдельной задаче нужно не так много данных. Задача, поэтому, сводится к тому, чтобы сделать предобученный NLP-алгоритм универсальным — таким, чтобы он фактически умел делать все, используя для обучения минимальное количество данных.\n",
    "\n",
    "Для решения этой задачи команда исследователей из компании OpenAI под руководством Тома Брауна (Tom Brown) представила GPT-3. Этот NLP-алгоритм основан на предыдущей версии, представленной в феврале прошлого года: GPT-2, одна из самых используемых и продвинутых NLP-моделей, обучена на 40 гигабайтах текста, а ее метазадача заключается в том, чтобы предсказывать следующее слово в тексте. Как и ее предшественник GPT, GPT-2 основана на архитектуре Transformer.\n",
    "\n",
    "Для обучения алгоритма исследователи собрали датасет из 570 гигабайтов текста, в который были включены данные проекта Common Crawl, вся Википедия, два датасета с книгами и вторая версия датасета WebText, содержащая тексты с веб-страниц (первую версию WebText использовали для обучения GPT-2). Исследователи обучили восемь разных моделей GPT-3: они отличались количеством параметров, которые модель устанавливала в ходе обучения (количество параметров, в свою очередь, зависело от количества слоев — при этом архитектура использовалась одна и та же). Внутри самой простой модели использовали 125 миллионов параметров, а в финальной GPT-3 — 175 миллиардов.\n",
    "\n",
    "Задача, которую GPT-3 нужно было выполнить, заключалась в ответе на вопрос или в выполнении задания. Это могло было быть, например, «написать стихотворение», «разобрать анаграмму» или «прочитать текст и ответить на вопрос». Предобученной GPT-3 для выполнения задания (всего заданий было 42), помимо формулировки задания, давали либо один пример, либо несколько примеров (классически от 10 до 100 — столько, сколько модели будет необходимо, хотя в некоторых заданиях модели хватало и пяти примеров).\n",
    "\n",
    "Несмотря на то, что точность каждого способа обучения модели возрастала с количеством определенных в модели параметров, обучение по нескольким примерам оказалось самым эффективным: по всем 42 заданиям точность при 175 миллиардах параметров составила почти 60 процентов. Например, при обучении на 64 примерах из датасета TriviaQA, который создан для обучения моделей понимать текст и отвечать на вопросы по прочитанному материалу, GPT-3 со 175 миллиардами параметров оказалась точна в 71,2 процента случаев — это чуть точнее, чем модель SOTA, которая обучена исключительно отвечать на вопросы по TriviaQA.\n",
    "\n",
    "По нескольким примерам предобученная GPT-3 может писать тексты на заданную тему, придумывать стихи в определенном стиле, разгадывать анаграммы, решать простые арифметические примеры, отвечать на вопросы по прочитанному тексту. Кроме того, модель может переводить на несколько языков: при сборе данных ученые не ограничили язык текстов, поэтому семь процентов всего датасета — тексты на иностранных языках, которые также используются моделью для перевода по нескольким примерам.\n",
    "\n",
    "Как и в случае с GPT-2, исследователи в препринте высказали свое беспокойство по поводу того, что разработанная ими модель может быть использована во вред — поэтому ее они пока что не предоставили. На странице разработчиков на GitHub можно найти кусок датасета и примеры заданий, которые использовались в работе.\n",
    "\n",
    "В последние годы OpenAI преуспел не только в NLP-алгоритмах: в прошлом году разработчики компании представили алгоритмы, которые могут придумывать новую музыку и собирать кубик Рубика.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8cb524c-2f2f-4dc0-9c43-e627b6b796f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions = [\"Как называется алгоритм, занимающийся написанием текстов?\",\n",
    "             \"Сколько текста было в обучающем датасете?\",\n",
    "             \"Какое ограничение у современных алгоритмов NLP?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bd0b381-74c5-416b-b618-389fee45f44e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как называется алгоритм, занимающийся написанием текстов?\n",
      "GPT-3\n",
      "Сколько текста было в обучающем датасете?\n",
      "570 гигабайтах текста\n",
      "Какое ограничение у современных алгоритмов NLP?\n",
      "зависимость от контекста\n"
     ]
    }
   ],
   "source": [
    "for q in questions:\n",
    "    print(q)\n",
    "    answer = squad_ru([text], [q])[0][0]\n",
    "    print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
