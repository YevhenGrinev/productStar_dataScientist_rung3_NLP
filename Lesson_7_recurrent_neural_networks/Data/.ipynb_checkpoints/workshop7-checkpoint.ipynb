{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определяем комментарии с оскорблениями при помощи LSTM + word2vec\n",
    "\n",
    "В этом воркшопе мы с вами применим все полученные знания для того, чтобы натренировать нейросеть, которая будет \"читать\" комментарии и отвечать на вопрос о том, содержится ли в комментарии оскорбление. Обучать её мы будем на комментариях с Пикабу, считая оскорбительными те комментарии, что были удалены модераторами по соответствующей причине.\n",
    "\n",
    "В прошлом воркшопе мы также создали word2vec-модель на основе текстов комментариев. Сегодня мы будем использовать её (ну почти её) в качестве ембеддинга для нашей нейросети.\n",
    "\n",
    "Ну от слов к делу: давайте познакомимся с датасетом и займёмся его подготовкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "np.random.seed(17)\n",
    "tf.random.set_seed(17)\n",
    "\n",
    "GPUs = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(GPUs[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# датасет хранится в бинарном файле, сохранённом при помощи pickle\n",
    "\n",
    "df = pd.read_pickle('offensive_comments.df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сразу перемешаем его\n",
    "\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                  comment  is_offensive\n",
       "53844  Взвешанное решение это хорошо. ТС молодец, вид...             0\n",
       "10034  Не надо, раздражение потом сильное. Друг расск...             0\n",
       "2592   Я бы реально пошел работать тогда водителем тр...             0\n",
       "19398  Судя по такому предположению, мсье из Петербурга?             0\n",
       "26446  Проблема матери в том что и она созависимая от...             0\n",
       "...                                                  ...           ...\n",
       "42297                        Тоже обычно с индии начинаю             0\n",
       "98710  Ты спорящий, навязывающий свое ебучее мнение и...             1\n",
       "34959  А ведь дохера заманчиво. Ведь каждый долбаный ...             0\n",
       "64753  Фрукт-фрукт, сиська-сиська, цветок-цветок. Тож...             0\n",
       "76399                                                                0\n",
       "\n",
       "[100000 rows x 2 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В столбце `comment` хранится текст комментария, а в столбце `is_offensive` отмечено, является ли он оскорбительным. Всего в датасете 100 тысяч комментариев. Проверим, какая часть из них оскорбительная:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_offensive'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего 10%, т.е. датасет несбалансированный. \n",
    "\n",
    "Для того, чтобы далее обучать на нём нейросеть, нужно его предобработать. Т.к. мы планируем использовать word2vec-модель, построенную ранее, проделаем все те же шаги препроцессинга: приведение к нижнему регистру, токенизация, выбрасывание стоп-слов, стеммизация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import RussianStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('russian'))\n",
    "stemmer = RussianStemmer()\n",
    "\n",
    "\n",
    "def preprocess(comment):\n",
    "    # сначала комментарий преобразуем к нижнему регистру\n",
    "    # заглавные буквы нам ни к чему\n",
    "    comment = comment.lower()\n",
    "\n",
    "    # токенизируем текст, получив список токенов\n",
    "    tokens = word_tokenize(comment)\n",
    "\n",
    "    # в списке оставим только те токены, что являются словами (выкинув, например, знаки препинания)\n",
    "    # также выкинем стоп-слова\n",
    "    # всё, что осталось, подвергнем стеммизации\n",
    "    tokens = [stemmer.stem(t) for t in tokens if t.isalpha() and t not in stop_words]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обработка займёт некоторое время\n",
    "\n",
    "df['comment'] = df['comment'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь пришло время закодировать полученные токены в соответствии с их номером в словаре word2vec-модели. После этого мы сможем подавать такие последовательности в Embedding-слой, чтобы вместо номеров получать вектора.\n",
    "\n",
    "Для этого задания потребуется чуть более тяжёлая модель, чем мы обучили ранее. Та была не самой точной и содержала достаточно мало слов, поэтому для этого воркшопа мы предобучили такую же модель, но на гораздо большем датасете и в течение большего количества времени. Её вектора хранятся в файле `vectors.w2v` и имеют размерность 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим подготовленную модель при помощи pickle\n",
    "\n",
    "with open('vectors.w2v', 'rb') as file:\n",
    "    wv = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нам необходимо пройтись по всем комментариям в датасете и преобразовать их в индексы: ищем соответствующее слово в словаре и записываем его индекс. Если слово в словаре отсутствует - просто пропускаем его. Вообще зачастую бывает полезно вместо неизвестных слов ставить какой-нибудь специальный токен [UNC] с собственным эмбеддингом, но мы опустим этот момент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment'] = df['comment'].apply(lambda x: [wv.vocab[word].index for word in x if word in wv.vocab])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После всех наших преобразований наверняка некоторые комментарии могли стать пустыми. Это, например, и комменты, состоящие только из картинок, и комментарии из неизвестных слов. Давайте посмотрим, сколько комментариев имеет нулевую длину и уберём их из датасета: они всё равно нам не понадобятся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9981"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сколько пустых комментов\n",
    "\n",
    "len(df.loc[df['comment'].map(len) == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оставим только строки с непустыми комментами\n",
    "\n",
    "df = df.loc[df['comment'].map(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1089436674479832"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# баланс датасета практически не изменился\n",
    "\n",
    "df['is_offensive'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Информацию в наш датасет мы будем подавать батчами, чтобы параллельно обрабатывать её при помощи тензорных операций. А это значит, что все тензоры в батче должны иметь одинаковый размер. В нашем случае одним обучающим примером является последовательность цифр, которая после прохождения через ембеддинг-слой превратится в последовательность векторов (матрицу). \n",
    "\n",
    "Чтобы все последовательности имели одинаковый размер, нам нужно обрезать слишком длинные последовательности, а короткие - дополнить специальным \"заполнителем\", который будет кодироваться просто нулевым вектором.\n",
    "\n",
    "Давайте определимся с оптимальной длиной комментария."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посчитаем длину комментариев\n",
    "\n",
    "comments_lengths = df['comment'].map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# построим распределение длины с помощью seaborn\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.distplot(comments_lengths[comments_lengths < 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, распределение имеет максимум где-то в районе 5-10 слов и очень длинный хвост. Очевидно, нет смысла жертвовать памятью и быстродействием нейросети ради совсем малого процента комментариев, поэтому давайте остановимся на 95%-ном квантиле длины. Будем надеяться, что в оставшихся 5% всё равно по началу комментария можно будет понять его характер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = int(comments_lengths.quantile(0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вышло по 54 слова в комментарии.\n",
    "\n",
    "Как уже было сказано, в качестве заполнителя используем нулевой вектор. Под него отведём отдельный индекс - последний в нашем списке. Индексы от 0 до \"кол-во слов - 1\" уже заняты, поэтому наш индекс будет соответствовать количеству слов в словаре. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_code = len(wv.vocab)  # код для нулевого вектора-заполнителя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в Keras есть специальная функция для приведения последовательностей к одной длине\n",
    "\n",
    "x = tf.keras.preprocessing.sequence.pad_sequences(df['comment'],\n",
    "                                                  maxlen=max_length,  # максимальная длина последовательности\n",
    "                                                  value=padding_code,  # код для заполнения отсутствующих ячеек\n",
    "                                                  padding='post',  # добавлять заполнитель в конце последовательности\n",
    "                                                  truncating='post')  # если последовательность длинная, отрезать конец"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 79831,    497,      0, ..., 199758, 199758, 199758],\n",
       "       [  8020,    127,      5, ..., 199758, 199758, 199758],\n",
       "       [   119,    669,     25, ..., 199758, 199758, 199758],\n",
       "       ...,\n",
       "       [ 45081,   3521,      3, ..., 199758, 199758, 199758],\n",
       "       [  5636,  16405,     33, ..., 199758, 199758, 199758],\n",
       "       [   409,     35,    345, ..., 199758, 199758, 199758]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90019, 54)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в y положим лейблы для наших комментариев\n",
    "\n",
    "y = np.array(df['is_offensive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет готов. Осталось только разделить его на 3 части для трейна, валидации и теста, как мы это делали и до этого."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(x, val_frac=0.15, test_frac=0.15):\n",
    "    x_train = x[:round((1 - val_frac - test_frac) * len(x))]\n",
    "    x_val = x[round((1 - val_frac - test_frac) * len(x)):round((1 - test_frac) * len(x))]\n",
    "    x_test = x[round((1 - test_frac) * len(x)):]\n",
    "    return x_train, x_val, x_test\n",
    "\n",
    "\n",
    "x_train, x_val, x_test = train_val_test_split(x)\n",
    "y_train, y_val, y_test = train_val_test_split(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно подготовить матрицу эмбеддинга, который будет выступать первым слоем в нашей нейросети. Напомним, что это матрица, в строках которой содержатся вектора для слов с соответствующими номерами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# размерность эмбеддинга - длина вектора в нашем word2vec\n",
    "embedding_dim = len(wv.get_vector('привет'))\n",
    "\n",
    "# количество слов в словаре - количество строк в матрице\n",
    "n_words = len(wv.vocab)\n",
    "\n",
    "# инициализируем матрицу нулями\n",
    "# сделаем в ней на 1 строку больше, чтобы в последней строке\n",
    "# остался нулевой ембеддинг для вектора-заполнителя\n",
    "embedding_matrix = np.zeros((n_words + 1, embedding_dim))\n",
    "\n",
    "# далее просто каждой строке матрицы присваиваем вектор для слова с соответствующим номером\n",
    "for word in wv.vocab:\n",
    "    embedding_matrix[wv.vocab[word].index] = wv.get_vector(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199759, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.80728012e-02, -4.17166436e-03,  1.48860073e+00, ...,\n",
       "         2.07133040e-01, -2.32561588e+00, -1.32097399e+00],\n",
       "       [-1.22191012e+00, -1.65977025e+00,  1.62026048e+00, ...,\n",
       "        -2.22401038e-01, -1.02031088e+00,  1.28245026e-01],\n",
       "       [ 4.17064056e-02,  8.75070810e-01,  6.10814214e-01, ...,\n",
       "         8.31370771e-01, -9.14068997e-01,  4.24623638e-01],\n",
       "       ...,\n",
       "       [ 4.62636128e-02,  2.09551863e-03,  1.81212146e-02, ...,\n",
       "        -2.68329885e-02, -3.64530571e-02, -4.98765372e-02],\n",
       "       [-3.97307379e-03,  3.84728308e-03, -7.45330155e-02, ...,\n",
       "        -4.55637202e-02,  2.82286890e-02, -2.28221389e-03],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настало время наконец построить нашу нейросеть. Первым слоем в ней будет выступать Embedding. Этот слой получает на вход номер слова и выдаёт соответствующую строку из своей матрицы весов. Мы сразу инициализируем его веса построенной матрицей и заморозим слой, чтобы веса не менялись в процессе тренировки.\n",
    "\n",
    "Далее положим 2 слоя Bidirectional LSTM из 16 юнитов (точнее, это размерность выходного вектора ячейки).\n",
    "\n",
    "В конце уже традиционно обычный Dense-слой для задачи бинарной классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # создаём эмбеддинг-слой соответствущей размерности\n",
    "    tf.keras.layers.Embedding(n_words + 1,\n",
    "                              embedding_dim,\n",
    "                              weights=[embedding_matrix],  # сразу инициализируем веса построенной матрицей\n",
    "                              trainable=False),  # больше тренировать этот слой не нужно\n",
    "    \n",
    "    # внутри \"обёртки\" Bidirectional уставляем LSTM с нужными настройками\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16,\n",
    "                                                       kernel_regularizer=tf.keras.regularizers.l2(0.001),\n",
    "                                                       recurrent_regularizer=tf.keras.regularizers.l2(0.0005),\n",
    "                                                       dropout=0.2,\n",
    "                                                       recurrent_dropout=0.1,  # дропаут между рекурентными итерациями\n",
    "                                                       return_sequences=True)),\n",
    "    \n",
    "    # обратите внимание: если мы хотим поместить сверху ещё один слой, в предыдущем слое\n",
    "    # необходимо указать параметр return_sequences=True, тогда следующий слой будет\n",
    "    # получать не только последний вектор, но и вектора на каждом шаге работы LSTM\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16,\n",
    "                                                       kernel_regularizer=tf.keras.regularizers.l2(0.001),\n",
    "                                                       recurrent_regularizer=tf.keras.regularizers.l2(0.0005),\n",
    "                                                       dropout=0.2,\n",
    "                                                       recurrent_dropout=0.1)),\n",
    "    \n",
    "    # обычный Dense-слой с сигмоидой\n",
    "    tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# т.к. датасет сильно несбалансированный, нам явно понадобится\n",
    "# больше метрик, чем просто accuracy\n",
    "\n",
    "accuracy = tf.keras.metrics.binary_accuracy\n",
    "precision = tf.keras.metrics.Precision()\n",
    "recall = tf.keras.metrics.Recall()\n",
    "\n",
    "\n",
    "def f1_metrics(y_true, y_pred):\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2 * ((prec * rec) / (prec + rec + 1e-7))\n",
    "\n",
    "\n",
    "# компилируем со стандартными настройками оптимизатора\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.binary_crossentropy,\n",
    "              metrics=[accuracy, precision, recall, f1_metrics])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всё готово, можно обучать!\n",
    "\n",
    "Но сразу предупреждаем: если вы планируете обучать на CPU, придётся тяжко. Если у вас нет GPU с CUDA, можете попробовать воспользоваться бесплатными сервисами вроде Google Colab или платформой Kaggle. \n",
    "\n",
    "Ну или можете просто загрузить в модель уже готовые веса далее =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-46c22993ef6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mstopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m model.fit(x_train, y_train,\n\u001b[0m\u001b[0;32m      6\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 696\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    697\u001b[0m             *args, **kwds))\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    960\u001b[0m           \u001b[1;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m           \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 962\u001b[1;33m             return autograph.converted_call(\n\u001b[0m\u001b[0;32m    963\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    594\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    597\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_whitelisted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m   \u001b[1;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    338\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    797\u001b[0m       outputs = reduce_per_replica(\n\u001b[0;32m    798\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1209\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1210\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1211\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1213\u001b[0m   \u001b[1;31m# TODO(b/151224785): Remove deprecated alias.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2583\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2584\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2585\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2587\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2943\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2944\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[1;32m-> 2945\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2947\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperimental_hints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_whitelisted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m   \u001b[1;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m         \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m       \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m       loss = self.compiled_loss(\n\u001b[0;32m    749\u001b[0m           y, y_pred, sample_weight, regularization_losses=self.losses)\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    370\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[1;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \"\"\"\n\u001b[1;32m--> 385\u001b[1;33m     return self._run_internal_graph(\n\u001b[0m\u001b[0;32m    386\u001b[0m         inputs, training=training, mask=mask)\n\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\wrappers.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask, initial_state, constants)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[0mforward_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackward_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m       y = self.forward_layer(forward_inputs,\n\u001b[0m\u001b[0;32m    644\u001b[0m                              initial_state=forward_state, **kwargs)\n\u001b[0;32m    645\u001b[0m       y_rev = self.backward_layer(backward_inputs,\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m   1124\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1126\u001b[1;33m       last_output, outputs, states = K.rnn(\n\u001b[0m\u001b[0;32m   1127\u001b[0m           \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m           \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mrnn\u001b[1;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[0;32m   4356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_ta_t\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4358\u001b[1;33m       final_outputs = control_flow_ops.while_loop(\n\u001b[0m\u001b[0;32m   4359\u001b[0m           \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4360\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   2685\u001b[0m   if (util.EnableControlFlowV2(ops.get_default_graph()) and\n\u001b[0;32m   2686\u001b[0m       not executing_eagerly):\n\u001b[1;32m-> 2687\u001b[1;33m     return while_v2.while_loop(\n\u001b[0m\u001b[0;32m   2688\u001b[0m         \u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2689\u001b[0m         \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, maximum_iterations, name, return_same_structure, back_prop)\u001b[0m\n\u001b[0;32m    267\u001b[0m           shape_invariants, expand_composites=True)[orig_loop_vars_range]\n\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m       outputs = _build_while_op(\n\u001b[0m\u001b[0;32m    270\u001b[0m           \u001b[0mflattened_loop_vars\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m           \u001b[0mcond_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py\u001b[0m in \u001b[0;36m_build_while_op\u001b[1;34m(loop_vars, cond_graph, body_graph, output_shapes, parallel_iterations, name)\u001b[0m\n\u001b[0;32m    429\u001b[0m       \u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m       \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_new_tf_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m       \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_new_tf_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m       \u001b[0moutput_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_util_v2.py\u001b[0m in \u001b[0;36mcreate_new_tf_function\u001b[1;34m(func_graph)\u001b[0m\n\u001b[0;32m     72\u001b[0m   func = function._EagerDefinedFunction(  # pylint: disable=protected-access\n\u001b[0;32m     73\u001b[0m       func_graph.name, func_graph, func_graph.inputs, func_graph.outputs, {})\n\u001b[1;32m---> 74\u001b[1;33m   \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36madd_to_graph\u001b[1;34m(self, g)\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 495\u001b[1;33m         \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    496\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\g0nzalez\\venv38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_add_function\u001b[1;34m(self, function)\u001b[0m\n\u001b[0;32m   3342\u001b[0m     gradient = (\n\u001b[0;32m   3343\u001b[0m         function._grad_func._c_func.func if function._grad_func else None)\n\u001b[1;32m-> 3344\u001b[1;33m     pywrap_tf_session.TF_GraphCopyFunction(self._c_graph, function._c_func.func,\n\u001b[0m\u001b[0;32m   3345\u001b[0m                                            gradient)\n\u001b[0;32m   3346\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='logs/LSTM', histogram_freq=1)\n",
    "annealing = tf.keras.callbacks.ReduceLROnPlateau(factor=0.2, patience=4, verbose=1, min_delta=0.01)\n",
    "stopping = tf.keras.callbacks.EarlyStopping(min_delta=0.001, patience=6, verbose=1)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_val, y_val),\n",
    "          batch_size=512,\n",
    "          epochs=30,\n",
    "          callbacks=[tensorboard, annealing, stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выполните загрузку предобученных весов, если вам не хочется ждать процесса обучения\n",
    "\n",
    "model.load_weights('weights_LSTM.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хоть модель и достаточно простая по меркам языковых задач, но вы уже наверняка ощутили, как долго она обучается по сравнению со всем тем, что мы встречали ранее. Когда же речь заходит о более сложных моделях, там уже без высокопроизводительных кластеров не обойтись, ведь это ещё для всех них нужно подбирать гиперпараметры и тестировать много вариантов архитектур!\n",
    "\n",
    "Ну что ж, напоследок давайте посмотрим, как модель работает на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 35s 83ms/step - loss: 0.1648 - binary_accuracy: 0.9483 - precision: 0.7816 - recall: 0.7056 - f1_metrics: 0.7358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1648002415895462,\n",
       " 0.9483078122138977,\n",
       " 0.7815912365913391,\n",
       " 0.705633819103241,\n",
       " 0.7357654571533203]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "70-80% precision и recall - не так уж и много по средним меркам задач классификации. Тем не менее, для работы с \"живым текстом\" для такой небольшой модели это неплохой показатель. Улучшением word2vec, усложнением модели, тщательным подбором гиперпараметров и всякими дополнительными плюшками вроде модификаций функции потерь или сглаживания лейблов можно было бы поднять результат ещё процентов на 10. Но это уже, конечно, совсем другие объёмы датасетов и совсем другое время тренировки сети."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
